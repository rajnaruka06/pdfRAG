{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.load import dumps, loads\n",
    "import re\n",
    "from collections import defaultdict, deque\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "# os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "        text += '\\n'\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = SentenceTransformerEmbeddings(model_name = \"all-mpnet-base-v2\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"C:\\\\Users\\\\rajna\\\\Desktop\\\\Studies\\\\Jupyter Notebook\\\\RAGS\\\\resources\\\\The Immortals of Meluha - Shiva Trilogy 1.pdf\"\n",
    "text = get_text_from_pdf(pdf_path)\n",
    "# chapters = text.split(\"CHAPTER\")\n",
    "# chapters.pop(0) ## As this would have content before the first chapter (prefeace, etc)\n",
    "# text = '\\n'.join(chapters)\n",
    "# del chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LLM and summarize each chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The hottest planet is Venus, also known as Earth's sister planet because it has a similar size and composition to our home world.\\nThe second closest star after the sun that can be seen with naked eye on earth\\nSirius A (also called Sirius) is one of two stars making up the dog constellation in the night sky. It’s not only the brightest visible object, but also it's a very close neighbor to our solar system.\\nThe hottest planet known so far has been discovered by NASA scientists using data from its Hubble Space Telescope and other telescopes around Earth on 18th April of this year (2021). The name given for that hot exoplanet is KELT-9b. It's located in the constellation Cygnus, about a thousand light-years away.\\nThe hottest planet known so far has been discovered by NASA scientists using data from its Hubble Space Telescope and other telescopes around Earth on 18th April of this year (2021). The name given for that hot exoplanet is KELT-9b. It's located in the constellation Cygnus, about a thousand light-years away.\\nThe hottest planet known so far has been discovered by NASA\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"You are a chapter summarizer. Given a chapter from a story, condense the main events, plot points, and character developments into a brief summary (around 500 words).\n",
    "Focus on capturing the essential information, omitting unnecessary details. Write in a clear and concise manner, using proper grammar and spelling. \n",
    "Assume the reader has not read the original chapter and provide enough context for them to understand the summary.\n",
    "\n",
    "Chapter: {chapter}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model_path = \"C:\\\\Users\\\\rajna\\\\Desktop\\\\Studies\\\\Jupyter Notebook\\\\RAGS\\\\resources\\\\Arcee-Scribe-IQ4_XS.gguf\"\n",
    "llm = GPT4All(model= model_path, device=\"cuda\", )\n",
    "summarizer_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "## Doing it because somehow diectly invoking llm with prompt results in a weired error.\n",
    "## If i invoke it with a string first and then with promopt, it works fine. Strange!\n",
    "llm.invoke(\"Please write the name of the hottest planet in the solar system.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_lev1 = []\n",
    "for doc in docs:\n",
    "    summaries_lev1.append(summarizer_chain.invoke(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(summaries_lev1) == len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a story synthesizer. \n",
    "You will be given a series of chapter summaries from a story. \n",
    "Your task is to read and understand these summaries, then generate a concise and coherent overall summary of the story (around 500 words). \n",
    "Identify the main plot, character arcs, and key events, and weave them together to create a cohesive narrative. \n",
    "Assume the reader has not read the original story and provide enough context for them to understand the overall plot. \n",
    "Use proper grammar, spelling, and punctuation. Your goal is to create a summary that accurately represents the story, highlighting its most important elements.\n",
    "\n",
    "summary_series: {summary_series}\n",
    "\n",
    "Overall Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "summarizer_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lev2 done. Number of summaries: 26\n",
      "lev3 done. Number of summaries: 6\n",
      "lev4 done. Number of summaries: 2\n",
      "lev5 done. Number of summaries: 1\n"
     ]
    }
   ],
   "source": [
    "all_summaries = defaultdict(list)\n",
    "all_summaries['lev1'] = summaries_lev1\n",
    "\n",
    "len_cur = len(summaries_lev1)\n",
    "cur_lev = 1\n",
    "\n",
    "while len_cur > 1:\n",
    "    cur_lev_name = f\"lev{cur_lev}\"\n",
    "    nxt_lev_name = f\"lev{cur_lev + 1}\"\n",
    "    for idx in range(0, len_cur, 5):\n",
    "        series = [f\"summary_{i}: {summary}\" for i, summary in enumerate(all_summaries[cur_lev_name][idx:idx+5])]\n",
    "        summary_series = '\\n'.join(series)\n",
    "        overall_summary = summarizer_chain.invoke({'summary_series' : summary_series})\n",
    "        all_summaries[nxt_lev_name].append(overall_summary)\n",
    "    \n",
    "    print(f\"{nxt_lev_name} done. Number of summaries: {len(all_summaries[nxt_lev_name])}\")\n",
    "    cur_lev += 1\n",
    "    len_cur = len(all_summaries[nxt_lev_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"The Immortals of Meluha\" is an epic tale set in ancient India during a time when survival was constantly challenged by arid lands and scarce water resources amidst violent tribes. The protagonist, Lord Shiva—a young warrior chief among these groups who faces numerous challenges navigating his complex world.\\n\\nShiva contemplates moving from their current tribe\\'s territory to search for fertile land promised by Meluhans but must decide whether or not accept a deal offered without any strings attached (summary_0). His journey towards Srinagar, the capital city of Kashmir renowned as paradise itself with rivers meandering through vast green fields under towering Chinar trees is fraught with moral dilemmas and personal growth.\\n\\nShiva\\'s relationship with Emperor Parvateshwar explores themes such as caste dynamics while navigating his own doubts about leadership. He encounters a mysterious old acquaintance named Sati who practices dance, leading to emotional depth in her performance despite lacking technical proficiency (summary_1). Shiva also faces challenges from neighboring societies threatened by Meluha\\'s superiority.\\n\\nThe story delves into personal relationships and philosophical discussions between characters including Parvateshwar on maintaining social harmony through respecting caste systems while believing equality should be applied universally. The', 'In \"The Immortals of Meluha,\" King Dasharatha summons Lord Ram for wisdom regarding an impending threat posed by Ravana. Major Uma enforces treaty and learns about Shiva\\'s absence, leading to a personal crisis when she accuses him.\\n\\nAs the story unfolds in chapters 1 through 3:\\n\\nChapter 2: \"Return\" introduces King Dasharatha who has summoned Lord Ram for wisdom regarding an impending threat posed by Ravana. \\n\\nIn Chapter 4 of this series (not provided), we can expect to see further developments as Major Uma\\'s personal crisis escalates and Shiva grapples with his sense of responsibility.\\n\\nThe story is set in ancient India, a land torn between duty for the king’s honorable rule over Ayodhya. Lord Ram returns from defeating Ravana but finds himself caught up amidst political intrigue as King Dasharatha seeks wisdom on how to handle an impending threat posed by Ravana\\'s forces.\\n\\nMeanwhile, Major Uma enforces a treaty with Ayodhya and learns of Shiva’s absence during her daughter\\'s death. This leads to personal turmoil for Major Uma when she accuses him in Chapter 3: \"']\n"
     ]
    }
   ],
   "source": [
    "print(all_summaries['lev4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a vectorstore (Indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thebook = [snippet for level in list(all_summaries.values()) for snippet in level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "thebook_embedded = embedding.embed_documents(thebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [\n",
    "    {\n",
    "        \"id\": f\"vec{idx + 1}\"\n",
    "        , \"values\": embedded_snippet\n",
    "        , \"metadata\": {\n",
    "            \"text\" : thebook[idx]\n",
    "        }\n",
    "    } for idx, embedded_snippet in enumerate(thebook_embedded)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Let's see embedding Dimention\"\n",
    "query_embedding = embedding.embed_query(query)\n",
    "dim = len(query_embedding)\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone()\n",
    "\n",
    "for prev_index in pc.list_indexes().names(): pc.delete_index(name=prev_index)\n",
    "\n",
    "index_name = \"bookpdfrag\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dim,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "            ) \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "index = pc.Index(name=index_name)\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0, len(vectors), 500):\n",
    "    index.upsert(vectors=vectors[idx:idx+500], namespace=pdf_path)\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(index = index, embedding = embedding.embed_query, text_key='text', namespace=pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the main confusion for shiva?\"\n",
    "similar_docs = vectorstore.similarity_search(query=user_query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in similar_docs:\n",
    "#     print(doc)\n",
    "#     print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I am thinking about Multi-Query and RAG Fusion for this.\n",
    "## RAG Fusion is for combining the results of different queries. and then summarizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_queries(rewritten_query):\n",
    "    rewritten_query = rewritten_query.split('\\n')\n",
    "    rewritten_query = [query.strip() for query in rewritten_query if query.strip() != '']\n",
    "    \n",
    "    all_queries = []\n",
    "    n = len(rewritten_query)\n",
    "    pattern = r\"rewritten_query_\\d+\"\n",
    "    idx = 0\n",
    "    while idx < n:\n",
    "        if re.match(pattern, rewritten_query[idx]) and idx + 1 < n: \n",
    "            all_queries.append(rewritten_query[idx + 1])\n",
    "        idx += 1\n",
    "    \n",
    "    return all_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_template = \"\"\"You are a query rewriter for a book snippet vector store. \n",
    "Given a user query, generate a set of rewritten queries that capture the same intent and meaning, specifically tailored to retrieve relevant snippets from a book.  \n",
    "Your task is to produce a list of {num_rewrites} rewritten queries that are semantically equivalent to the original query, with a focus on querying the book snippet vector store.\n",
    "\n",
    "For each rewritten query, focus on rephrasing the original query using different words, phrases, and sentence structures while preserving the core meaning and intent. \n",
    "Consider synonyms, paraphrasing, and alternative ways of expressing the same idea.\n",
    "\n",
    "Output format: A list of {num_rewrites} rewritten queries, each on a new line, like this:\n",
    "\n",
    "rewritten_query_1\n",
    "rewritten_query_2\n",
    "rewritten_query_3\n",
    "\n",
    "Example input: \"What is the main plot of the story?\"\n",
    "Example output:\n",
    "\n",
    "\"What is the central conflict in the novel?\"\n",
    "\"How do the characters' motivations drive the plot forward?\"\n",
    "\"What are the key events that shape the narrative's climax?\"\n",
    "\n",
    "User Input: {user_query}.\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "multiquery_prompt = ChatPromptTemplate.from_template(multiquery_template)\n",
    "multiquery_chain = multiquery_prompt | llm | StrOutputParser() | clean_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is the main confusion for shiva?\"\n",
    "rewritten_queries = multiquery_chain.invoke({'user_query': user_query, 'num_rewrites': 5})\n",
    "all_queries = [user_query] + rewritten_queries\n",
    "# all_queries_embedded = embedding.embed_documents(all_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the main confusion for shiva?',\n",
       " 'What causes Shiva to experience significant turmoil?',\n",
       " 'Can you identify what leads to major distress in Shiva’s life?',\n",
       " 'What are the primary sources of chaos and uncertainty that affect Shiva deeply',\n",
       " 'Identify which events or situations provoke intense confusion for Shiva.',\n",
       " \"What factors contribute significantly to significant emotional upheaval in Shiva's experiences?\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag Fusion for Final Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\" Reciprocal_rank_fusion that takes multiple lists of ranked documents \n",
    "        and an optional parameter k used in the RRF formula \"\"\"\n",
    "    \n",
    "    fused_scores = defaultdict(float)\n",
    "    for docs in results:\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_snippets = retriever.map().invoke(all_queries)\n",
    "context = '\\n'.join([doc.page_content for doc, score in reciprocal_rank_fusion(related_snippets)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_template = \"\"\"You are a book expert. \n",
    "You have been provided with a context which is a compilation of snippets from a fictional book. \n",
    "Your task is to answer a user query based on the information contained within these snippets.\n",
    "\n",
    "Your answer should be a concise and accurate response to the user query, based solely on the information provided in the context snippets. \n",
    "Do not rely on external knowledge or make assumptions beyond what is explicitly stated in the snippets.\n",
    "\n",
    "When answering the query, consider the following:\n",
    "\n",
    "The context snippets may not provide a complete picture of the book, so be careful not to make inferences or fill in gaps with external knowledge.\n",
    "Focus on the specific details mentioned in the snippets that are relevant to the user query.\n",
    "If the context snippets do not provide enough information to answer the query, indicate that the answer is unknown or unclear.\n",
    "Output format: A single answer to the user query, in a concise and clear format.\n",
    "\n",
    "Example input:\n",
    "Context Snippets:\n",
    "\"The novel is set in a dystopian future where the government has total control.\n",
    "The main character, Maya, is a 25-year-old rebel fighting against the government.\"\n",
    "The story takes place in the year 2087.\"\n",
    "\n",
    "User Query: \n",
    "\"What is the age of the main character?\"\n",
    "\n",
    "Example Output: \n",
    "\"The main character, Maya, is 25 years old.\"\n",
    "\n",
    "Context Snippets: \n",
    "{context}\n",
    "\n",
    "User Query: {user_query}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_template(generation_template)\n",
    "generation_chain = generation_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary source of Shiva's confusion in these snippets revolves around his emotional turmoil following Sati’s death. He grapples with guilt over failing to save her and experiences severe physical pain as well, both from wounds sustained during battle against demons like Lord Rudra.\n",
      "\n",
      "In the context provided by Summary 4 (\"Shri Ram\"), Shiva is in a state of deep distress after witnessing his wife Sati's death at the hands of a monster while he could only watch helplessly. This traumatic event has left him traumatized, causing both physical and emotional pain for which he struggles to find solace.\n",
      "\n",
      "The incident also affects those around Shiva significantly—including Parvateshwar (his friend), Ayurvati (a physician who tends him) and Drapaku are mentioned as being affected by his suffering. His confusion stems from the profound grief over losing Sati, coupled with a sense of failure in failing to protect her.\n",
      "\n",
      "In summary, Shiva's main confusion is rooted deeply within emotional turmoil following an inability to save someone he loves during a traumatic event—a struggle that affects both him and those around him significantly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = generation_chain.invoke({'context': context, 'user_query': user_query})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory - 1\n",
    "- Tried to only track previous queries but it does not work. The rewritten queries are very generic\n",
    "- Need track of responses as well to rewrite \"Who is shiva's love interest\" instead of \"Who is our main character's love interest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiquery_template = \"\"\"You are a query rewriter for a book snippet vector store. \n",
    "# Given a user query, generate a set of rewritten queries that capture the same intent and meaning, specifically tailored to retrieve relevant snippets from a book.  \n",
    "# Your task is to produce a list of {num_rewrites} rewritten queries that are semantically equivalent to the original query, with a focus on querying the book snippet vector store.\n",
    "\n",
    "# For each rewritten query, focus on rephrasing the original query using different words, phrases, and sentence structures while preserving the core meaning and intent. \n",
    "# Consider synonyms, paraphrasing, and alternative ways of expressing the same idea.\n",
    "# By leveraging the context from previous queries, you can create rewritten queries that are more targeted and effective at retrieving relevant snippets from the book.\n",
    "\n",
    "# Output format: A list of {num_rewrites} rewritten queries, each on a new line, like this:\n",
    "\n",
    "# rewritten_query_1\n",
    "# rewritten_query_2\n",
    "# rewritten_query_3\n",
    "\n",
    "# Example input1: \"What is the name of his love interest?\"\n",
    "# Previous queries: \"What is the setting of the novel?\", \"Who is the main character?\"\n",
    "# Example output:\n",
    "\n",
    "# 1. \"Who is the romantic partner of the main character in the novel?\"\n",
    "# 2. \"What is the name of the female character that the main character falls in love with?\"\n",
    "# 3. \"What is the relationship like between the main character and his love interest in the novel?\"\n",
    "\n",
    "# Example input1: \"What is the main conflict between the two characters?\"\n",
    "# Previous queries: \"What is the setting of the novel?\", \"Who is the main character?\", \"Who is the main character's rival?\", \"What is the main character's goal?\"\n",
    "# Example output:\n",
    "\n",
    "# 1. \"What is the central struggle between the main character and their rival in the novel's setting?\"\n",
    "# 2. \"How does the main character's goal relate to the conflict with their rival?\"\n",
    "# 3. \"What obstacles does the main character face in achieving their goal due to their rival?\"\n",
    "\n",
    "# Example input3: \"What is the significance of the magical artifact?\"\n",
    "# Previous queries: \"What is the setting of the novel?\", \"Who is the main character?\", \"What is the main character's goal?\", \"What is the main character's magical ability?\", \"How does the main character acquire the magical artifact?\"\n",
    "# Example output:\n",
    "\n",
    "# 1. \"What role does the magical artifact play in the main character's quest in the novel's setting?\"\n",
    "# 2. \"How does the main character's magical ability relate to the significance of the artifact?\"\n",
    "# 3. \"What is the main character's goal in using the magical artifact?\"\n",
    "\n",
    "# User Input: {user_query}.\n",
    "# Previous Queries: {previous_queries}\n",
    "# Output:\n",
    "# \"\"\"\n",
    "\n",
    "# multiquery_prompt = ChatPromptTemplate.from_template(multiquery_template)\n",
    "# multiquery_chain = multiquery_prompt | llm | StrOutputParser() | (lambda x : [qn for qn in x.split('\\n') if qn and qn[0].isdigit()])\n",
    "\n",
    "# # Rewritten queries with previous queries are not as good as expected. Might try with different LLM or prompt or few shot learning.\n",
    "\n",
    "# previous_questions = questions[:1]\n",
    "# for qn in questions[1:]:\n",
    "#     rewritten_queries = multiquery_chain.invoke({'user_query': qn, 'num_rewrites': 5, 'previous_queries': ', '.join(previous_questions)})\n",
    "#     previous_questions.append(qn)\n",
    "#     print(rewritten_queries)\n",
    "#     print(\"-\"*50)\n",
    "\n",
    "\n",
    "# generation_template = \"\"\"You are a book expert. \n",
    "# You have been provided with a context which is a compilation of snippets from a fictional book. \n",
    "# Your task is to answer a user query based on the information contained within these snippets.\n",
    "\n",
    "# Your answer should be a concise and accurate response to the user query, based solely on the information provided in the context snippets. \n",
    "# Do not rely on external knowledge or make assumptions beyond what is explicitly stated in the snippets.\n",
    "\n",
    "# When answering the query, consider the following:\n",
    "\n",
    "# The context snippets may not provide a complete picture of the book, so be careful not to make inferences or fill in gaps with external knowledge.\n",
    "# Focus on the specific details mentioned in the snippets that are relevant to the user query.\n",
    "# If the context snippets do not provide enough information to answer the query, indicate that the answer is unknown or unclear.\n",
    "# Output format: A single answer to the user query, in a concise and clear format.\n",
    "\n",
    "# Example input:\n",
    "# Context Snippets:\n",
    "# \"The novel is set in a dystopian future where the government has total control.\n",
    "# The main character, Maya, is a 25-year-old rebel fighting against the government.\"\n",
    "# The story takes place in the year 2087.\"\n",
    "\n",
    "# User Query: \n",
    "# \"What is the age of the main character?\"\n",
    "\n",
    "# Example Output: \n",
    "# \"The main character, Maya, is 25 years old.\"\n",
    "\n",
    "# Context Snippets: \n",
    "# {context}\n",
    "\n",
    "# previous_queries: \n",
    "# {previous_queries}\n",
    "\n",
    "# Current User Query: {user_query}\n",
    "\n",
    "# Output:\n",
    "# \"\"\"\n",
    "\n",
    "# generation_prompt = ChatPromptTemplate.from_template(generation_template)\n",
    "# generation_chain = generation_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "# previous_queries = []\n",
    "\n",
    "# def answer_query(user_query):\n",
    "#     global previous_queries\n",
    "    \n",
    "#     rewritten_queries = multiquery_chain.invoke({'user_query': user_query, 'num_rewrites': 5, 'previous_queries': ', '.join(previous_queries)})\n",
    "#     all_queries = [user_query] + rewritten_queries\n",
    "\n",
    "#     related_snippets = retriever.map().invoke(all_queries)\n",
    "#     context = '\\n'.join([doc.page_content for doc, score in reciprocal_rank_fusion(related_snippets)])\n",
    "    \n",
    "#     response = generation_chain.invoke({'context': context, 'user_query': user_query, 'previous_queries': ', '.join(previous_queries)})\n",
    "#     previous_queries.append(user_query)\n",
    "#     return response\n",
    "\n",
    "# def clear_memory():\n",
    "#     global previous_queries\n",
    "#     previous_queries = []\n",
    "\n",
    "\n",
    "# questions = [\n",
    "#     \"Who is the protagonist of the story? and what is the main plot?\",\n",
    "#     \"Does he face any conflicts?\",\n",
    "#     \"How does he overcome them?\",\n",
    "#     \"Who is his love interest?\",\n",
    "#     \"What are her characteristics?\",\n",
    "# ]\n",
    "\n",
    "# for question in questions:\n",
    "#     response = answer_query(question)\n",
    "#     print(\n",
    "#         f\"\"\"Question: {question}\n",
    "#         Answer: {response}\n",
    "#         \"\"\"\n",
    "#     )\n",
    "#     print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiquery_template = \"\"\"**Context:**\n",
    "\n",
    "* **User Queries:** {previous_queries} (List of all user queries so far)\n",
    "* **System Responses:** {previous_responses} (List of all system responses to the user queries)\n",
    "\n",
    "**User Input:** {user_query}\n",
    "\n",
    "**Task:**\n",
    "\n",
    "Based on the provided context and the user's current query, generate a set of {num_rewrites} rewritten queries that capture the same intent and meaning, specifically tailored to retrieve relevant snippets from the book. \n",
    "\n",
    "**Focus:**\n",
    "\n",
    "* Utilize the information from the book snippet context, user queries, and system responses to formulate more targeted and effective rewritten queries.\n",
    "* Leverage synonyms, paraphrasing, and alternative ways of expressing the same idea.\n",
    "* Focus on rephrasing the original query using different words, phrases, and sentence structures while preserving the core meaning and intent.\n",
    "\n",
    "**Output Format:**\n",
    "\n",
    "A list of {num_rewrites} rewritten queries, each on a new line, like this:\n",
    "\n",
    "rewritten_query_1\n",
    "rewritten_query_2\n",
    "rewritten_query_3\n",
    "\n",
    "Output:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "multiquery_prompt = ChatPromptTemplate.from_template(multiquery_template)\n",
    "multiquery_chain = multiquery_prompt | llm | StrOutputParser() | (lambda x : [qn for qn in x.split('\\n') if len(qn) > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous_questions = [user_query]\n",
    "# previous_responses = [response]\n",
    "# rewritten_queries = multiquery_chain.invoke({\n",
    "#         'user_query': \"How does he overcome them?\", \n",
    "#         'num_rewrites': 5, \n",
    "#         'previous_queries': ', '.join(previous_questions),\n",
    "#         'previous_responses': ', '.join(previous_responses)\n",
    "#     })\n",
    "# print(rewritten_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_template = \"\"\"**Context:**\n",
    "\n",
    "* **Previous User Queries:** {previous_queries} (List of all user queries so far)\n",
    "* **Previous System Responses:** {previous_responses} (List of all system responses to the user queries)\n",
    "* **Current Book Snippet:** {current_context} (The most recent retrieved snippet based on the user query)\n",
    "\n",
    "**User Input:** {user_query}\n",
    "\n",
    "**Task:**\n",
    "\n",
    "As a book expert, analyze the provided context, including previous user queries, system responses, and the current book snippet, to answer the user's current query.\n",
    "\n",
    "**Focus:**\n",
    "\n",
    "* Generate a concise and accurate response to the user's query based solely on the information within the provided context.\n",
    "* Don't use external knowledge or assumptions beyond the explicit details in the snippets and responses.\n",
    "* Prioritize specific details mentioned in the context relevant to the user's question.\n",
    "* If the answer remains unknown or unclear based on the context, acknowledge that information is limited.\n",
    "\n",
    "**Output Format:**\n",
    "\n",
    "A single, clear, and concise answer to the user's query.\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "generation_prompt = ChatPromptTemplate.from_template(generation_template)\n",
    "generation_chain = generation_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_memory():\n",
    "    global previous_queries, previous_responses\n",
    "    previous_queries = deque([])\n",
    "    previous_responses = deque([])\n",
    "\n",
    "def answer_query(user_query):\n",
    "    global previous_queries, previous_responses\n",
    "    \n",
    "    rewritten_queries = multiquery_chain.invoke({\n",
    "        'user_query': \"How does he overcome them?\", \n",
    "        'num_rewrites': 5, \n",
    "        'previous_queries': ', '.join(previous_queries),\n",
    "        'previous_responses': ', '.join(previous_responses)\n",
    "        })\n",
    "    \n",
    "    all_queries = [user_query] + rewritten_queries\n",
    "\n",
    "    related_snippets = retriever.map().invoke(all_queries)\n",
    "    context = '\\n'.join([doc.page_content for doc, score in reciprocal_rank_fusion(related_snippets)])\n",
    "    \n",
    "    response = generation_chain.invoke({\n",
    "        'previous_queries': ', '.join(previous_queries)\n",
    "        , 'previous_responses': ', '.join(previous_responses)\n",
    "        , 'current_context': context\n",
    "        , 'user_query': user_query\n",
    "    })\n",
    "\n",
    "    previous_queries.append(user_query)\n",
    "    previous_responses.append(response)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who is the protagonist of the story? and what is the main plot?\n",
      "        Answer: The protagonist of this story appears to be Lord Shiva (also known as Neelkanth), who embarks upon an epic journey through Meluha. The main plot revolves around his leadership challenges in a world beset by formidable enemies while also confronting personal doubts and tragedies, including the loss of his beloved wife Sati.\n",
      "\n",
      "This analysis is based on references to Shiva's role as Emperor Parvateshwar (Shiva’s general) leading an army across Swadweep. His journey involves navigating complex societal issues such as fairness in treatment among different groups like Vikarma people and understanding leadership within a stable society that allows for gradual change while providing freedom.\n",
      "\n",
      "The story also touches on themes of faith, destiny, personal responsibility versus fate-driven suffering (as seen with Sati's life-threatening wounds), and the balance between stability required by successful societies. Shiva’s internal struggle is evident in his contemplation over societal practices he finds unfair as well as dealing personally with loss.\n",
      "\n",
      "The narrative blends ancient myths intertwined within a modern science fiction setting, exploring how these themes play out through various characters' journeys including gods and goddesses navigating personal challenges while battling demons. The main plot revolves around Emperor Parvateshwar's investigation into\n",
      "        \n",
      "--------------------------------------------------\n",
      "deque(['Who is the protagonist of the story? and what is the main plot?'])\n",
      "Question: Does he face any conflicts?\n",
      "        Answer: Yes, Lord Shiva faces numerous conflicts throughout his journey. These include leadership challenges in a world beset by formidable enemies while also confronting personal doubts following tragedies such as losing his beloved wife Sati (summary_0). He navigates complex societal issues like fairness and understanding of leadership within stable societies that allow for gradual change, providing freedom to its people.\n",
      "\n",
      "Shiva's internal struggle is evident through contemplation over unfair practices he finds in society. His journey involves battling demons while also dealing with personal loss as seen when his brother Brahaspati dies (summary_3). He grapples with guilt and self-doubt about starting a war, but these conflicts are comforted by the wisdom of an old Pandit who explains that every action has its purpose.\n",
      "\n",
      "Shiva's encounters in crowded streets filled with shopkeepers negotiating over trivial amounts lead to introspection on his potential benefits as Suryavanshi under Parvateshwar (summary_0). He also experiences empathy and humility when interacting with characters like an old man begging at Lord Ram’s doorstep, realizing that people are not inherently evil but live in harsh systems.\n",
      "\n",
      "These conflicts shape Shiva's journey of self-discovery as he learns about his role from the Pandit while recognizing\n",
      "        \n",
      "--------------------------------------------------\n",
      "deque(['Who is the protagonist of the story? and what is the main plot?', 'Does he face any conflicts?'])\n",
      "Question: How does he overcome them?\n",
      "        Answer: To overcome his internal conflicts of guilt over starting a war against Swadweepans despite losing his brother Brahaspati (summary_3), Shiva seeks wisdom from an old Pandit. The Pandit explains that\n",
      "        \n",
      "--------------------------------------------------\n",
      "deque(['Does he face any conflicts?', 'How does he overcome them?'])\n",
      "Question: Who is his love interest?\n",
      "        Answer: Shiva’s love interest appears to be Parvateshwar. This relationship adds depth as it involves a complex dynamic of leadership challenges within society while also confronting personal doubts following tragedies such as losing his beloved wife Sati (summary_0). The interactions between Shiva and Parvateshwar highlight the themes of empathy, humility for those less fortunate than him.\n",
      "\n",
      "This answer is derived from:\n",
      "1. Summary 0: Mentions that Shiva faces leadership challenges in a world beset by formidable enemies while also confronting personal doubts following tragedies such as losing his beloved wife Sati.\n",
      "2. The mention and interaction between Parvateshwar, who adds depth to the relationship through complex dynamics of society's struggles with evil forces.\n",
      "\n",
      "The answer is consistent within this context without requiring external knowledge or assumptions beyond what has been explicitly mentioned in previous system responses (summary_0) about Shiva’s personal journey involving his wife Sati and leadership challenges.\n",
      "        \n",
      "--------------------------------------------------\n",
      "deque(['How does he overcome them?', 'Who is his love interest?'])\n",
      "Question: What are her characteristics?\n",
      "        Answer: The characteristics of Sati are not explicitly detailed within this provided text snippet. However, it can be inferred from previous system responses (summary_0) about Shiva’s relationship with her that she is deeply loved by him but also a source of personal doubt and guilt due to tragic events involving their marriage.\n",
      "\n",
      "In summary:\n",
      "- **Love Interest:** Sati appears as the love interest for Shiva, adding depth through complex dynamics.\n",
      "- **Tragic Events:** The loss of his beloved wife leads to significant internal conflict within Shiva's character. \n",
      "\n",
      "The provided text does not offer specific details about her characteristics beyond these inferred points from previous responses and interactions between characters.\n",
      "\n",
      "Therefore:\n",
      "*Sati is deeply loved by Shiva but also a source of personal guilt due to tragic events involving their marriage.*\n",
      "        \n",
      "--------------------------------------------------\n",
      "deque(['Who is his love interest?', 'What are her characteristics?'])\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"Who is the protagonist of the story? and what is the main plot?\",\n",
    "    \"Does he face any conflicts?\",\n",
    "    \"How does he overcome them?\",\n",
    "    \"Who is his love interest?\",\n",
    "    \"What are her characteristics?\",\n",
    "]\n",
    "\n",
    "init_memory()\n",
    "\n",
    "for question in questions:\n",
    "    response = answer_query(question)\n",
    "    print(\n",
    "        f\"\"\"Question: {question}\n",
    "        Answer: {response}\n",
    "        \"\"\"\n",
    "    )\n",
    "    print('-'*50)\n",
    "\n",
    "    if len(previous_queries) > 2:\n",
    "        previous_queries.popleft()\n",
    "        previous_responses.popleft()\n",
    "    \n",
    "    print(previous_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
